{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b1ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config('spark.sql.warehouse.dir',f'/user/{username}/warehouse'). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11de4fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO,2015-8-8 20:49:22\n",
      "WARN,2015-1-14 20:05:00\n",
      "INFO,2017-6-14 00:08:35\n",
      "INFO,2016-1-18 11:50:14\n",
      "DEBUG,2017-7-1 12:55:02\n",
      "INFO,2014-2-26 12:34:21\n",
      "INFO,2015-7-12 11:13:47\n",
      "INFO,2017-4-15 01:20:18\n",
      "DEBUG,2016-11-2 20:19:23\n",
      "INFO,2012-8-20 10:09:44\n",
      "DEBUG,2014-4-22 21:30:49\n",
      "WARN,2013-12-6 17:54:15\n",
      "DEBUG,2017-1-12 10:47:02\n",
      "DEBUG,2016-6-25 11:06:42\n",
      "ERROR,2015-6-28 19:25:05\n",
      "DEBUG,2012-6-24 01:06:37\n",
      "INFO,2014-12-9 09:53:54\n",
      "DEBUG,2015-11-8 19:20:08\n",
      "INFO,2017-7-21 18:34:18\n",
      "DEBUG,2014-12-26 06:38:42\n",
      "DEBUG,2013-1-6 16:56:43\n",
      "INFO,2015-10-8 11:33:25\n",
      "INFO,2016-11-18 09:47:31\n",
      "DEBUG,2015-2-6 16:24:07\n",
      "WARN,2016-7-26 18:54:43\n",
      "INFO,2012-10-18 14:35:19\n",
      "DEBUG,2012-4-26 14:26:50\n",
      "DEBUG,2013-9-28 20:27:13\n",
      "INFO,2017-8-20 13:17:27\n",
      "INFO,2015-4-13 09:28:17\n",
      "DEBUG,2015-7-17 00:49:27\n",
      "DEBUG,2014-7-26 02:33:09\n",
      "INFO,2016-1-13 09:51:57\n",
      "DEBUG,2015-1-14 08:55:30\n",
      "DEBUG,2016-1-20 03:47:06\n",
      "DEBUG,2013-7-8 21:00:50\n",
      "DEBUG,2012-5-22 11:43:57\n",
      "DEBUG,2013-3-20 06:14:50\n",
      "DEBUG,2017-7-13 15:35:11\n",
      "DEBUG,2013-1-21 20:20:25\n",
      "DEBU"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/logdata1m.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c619d97",
   "metadata": {},
   "source": [
    "## We need to analyze these log and find some inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa638652",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = [(\"INFO\",\"2015-8-8 20:49:22\"),\n",
    "(\"WARN\",\"2015-1-14 20:05:00\"),\n",
    "(\"INFO\",\"2017-6-14 00:08:35\"),\n",
    "(\"INFO\",\"2016-1-18 11:50:14\"),\n",
    "(\"DEBUG\",\"2017-7-1 12:55:02\"),\n",
    "(\"INFO\",\"2014-2-26 12:34:21\"),\n",
    "(\"INFO\",\"2015-7-12 11:13:47\"),\n",
    "(\"INFO\",\"2017-4-15 01:20:18\"),\n",
    "(\"DEBUG\",\"2016-11-2 20:19:23\"),\n",
    "(\"INFO\",\"2012-8-20 10:09:44\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069da6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.createDataFrame(log_data).toDF(\"loglevel\",\"logtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3639a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|loglevel|           logtime|\n",
      "+--------+------------------+\n",
      "|    INFO| 2015-8-8 20:49:22|\n",
      "|    WARN|2015-1-14 20:05:00|\n",
      "|    INFO|2017-6-14 00:08:35|\n",
      "|    INFO|2016-1-18 11:50:14|\n",
      "|   DEBUG| 2017-7-1 12:55:02|\n",
      "|    INFO|2014-2-26 12:34:21|\n",
      "|    INFO|2015-7-12 11:13:47|\n",
      "|    INFO|2017-4-15 01:20:18|\n",
      "|   DEBUG|2016-11-2 20:19:23|\n",
      "|    INFO|2012-8-20 10:09:44|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f593f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce8e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feadc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log_df = log_df.withColumn(\"logtime\",to_timestamp(\"logtime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c9679a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b7e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d659ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca7297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32ddffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d214717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|loglevel|month|\n",
      "+--------+-----+\n",
      "|    INFO|   08|\n",
      "|    WARN|   01|\n",
      "|    INFO|   06|\n",
      "|    INFO|   01|\n",
      "|   DEBUG|   07|\n",
      "|    INFO|   02|\n",
      "|    INFO|   07|\n",
      "|    INFO|   04|\n",
      "|   DEBUG|   11|\n",
      "|    INFO|   08|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eda71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|loglevel|month|\n",
      "+--------+-----+\n",
      "|    INFO|  Aug|\n",
      "|    WARN|  Jan|\n",
      "|    INFO|  Jun|\n",
      "|    INFO|  Jan|\n",
      "|   DEBUG|  Jul|\n",
      "|    INFO|  Feb|\n",
      "|    INFO|  Jul|\n",
      "|    INFO|  Apr|\n",
      "|   DEBUG|  Nov|\n",
      "|    INFO|  Aug|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc24aa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|loglevel|   month|total_occurence|\n",
      "+--------+--------+---------------+\n",
      "|    INFO|    June|              1|\n",
      "|   DEBUG|    July|              1|\n",
      "|    INFO|February|              1|\n",
      "|    WARN| January|              1|\n",
      "|    INFO|  August|              2|\n",
      "|   DEBUG|November|              1|\n",
      "|    INFO|   April|              1|\n",
      "|    INFO| January|              1|\n",
      "|    INFO|    July|              1|\n",
      "+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime,'MMMM') as month, count(*) as total_occurence from serverlogs group by loglevel, month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2e99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logschema = \"loglevel string, logtime timestamp\"\n",
    "logs_df = spark.read \\\n",
    ".format('csv') \\\n",
    ".schema(logschema) \\\n",
    ".load(\"/public/trendytech/datasets/logdata1m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61de5cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846f4a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7d0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0437275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40080400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfea298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------------+\n",
      "|loglevel|    month|total_occurence|\n",
      "+--------+---------+---------------+\n",
      "|    WARN|     June|           8191|\n",
      "|    INFO|     June|          29143|\n",
      "|   ERROR| November|           3389|\n",
      "|   FATAL|  January|             94|\n",
      "|    WARN| December|           8328|\n",
      "|    WARN|    March|           8165|\n",
      "|   DEBUG|     July|          42085|\n",
      "|   ERROR|    April|           4107|\n",
      "|   ERROR|  January|           4054|\n",
      "|   FATAL|September|             81|\n",
      "|   FATAL|    April|             83|\n",
      "|    INFO|September|          29038|\n",
      "|   FATAL| November|          16797|\n",
      "|   FATAL|  October|             92|\n",
      "|    INFO| February|          28983|\n",
      "|    WARN|    April|           8277|\n",
      "|   DEBUG| December|          41749|\n",
      "|   FATAL| December|             94|\n",
      "|    WARN|      May|           8403|\n",
      "|   ERROR|     June|           4059|\n",
      "+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d45a3594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|loglevel|   month|total_occurence|\n",
      "+--------+--------+---------------+\n",
      "|   FATAL|   April|             83|\n",
      "|   ERROR|   April|           4107|\n",
      "|    WARN|   April|           8277|\n",
      "|    INFO|   April|          29302|\n",
      "|   DEBUG|   April|          41869|\n",
      "|   ERROR|  August|           3987|\n",
      "|   FATAL|  August|             80|\n",
      "|    INFO|  August|          28993|\n",
      "|   DEBUG|  August|          42147|\n",
      "|    WARN|  August|           8381|\n",
      "|   FATAL|December|             94|\n",
      "|   DEBUG|December|          41749|\n",
      "|    WARN|December|           8328|\n",
      "|    INFO|December|          28874|\n",
      "|   ERROR|December|           4106|\n",
      "|   DEBUG|February|          41734|\n",
      "|   ERROR|February|           4013|\n",
      "|   FATAL|February|             72|\n",
      "|    WARN|February|           8266|\n",
      "|    INFO|February|          28983|\n",
      "+--------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month\n",
    "order by month\"\"\").show()\n",
    "## incorrect sorting ( done in alphabetical order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3eb1eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------------+\n",
      "|loglevel|   month|month_num|total_occurence|\n",
      "+--------+--------+---------+---------------+\n",
      "|   ERROR| January|        1|           4054|\n",
      "|   DEBUG| January|        1|          41961|\n",
      "|    INFO| January|        1|          29119|\n",
      "|    WARN| January|        1|           8217|\n",
      "|   FATAL| January|        1|             94|\n",
      "|   DEBUG| October|       10|          41936|\n",
      "|    WARN| October|       10|           8226|\n",
      "|   ERROR| October|       10|           4040|\n",
      "|   FATAL| October|       10|             92|\n",
      "|    INFO| October|       10|          29018|\n",
      "|   DEBUG|November|       11|          33366|\n",
      "|    WARN|November|       11|           6616|\n",
      "|   FATAL|November|       11|          16797|\n",
      "|   ERROR|November|       11|           3389|\n",
      "|    INFO|November|       11|          23301|\n",
      "|    INFO|December|       12|          28874|\n",
      "|   ERROR|December|       12|           4106|\n",
      "|   FATAL|December|       12|             94|\n",
      "|    WARN|December|       12|           8328|\n",
      "|   DEBUG|December|       12|          41749|\n",
      "+--------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "date_format(logtime, 'M') as month_num,\n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month, month_num\n",
    "order by month_num\"\"\").show()\n",
    "\n",
    "## incorrect sorting, because it's in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72939d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------------+\n",
      "|loglevel|   month|month_num|total_occurence|\n",
      "+--------+--------+---------+---------------+\n",
      "|    WARN| January|        1|           8217|\n",
      "|   ERROR| January|        1|           4054|\n",
      "|   DEBUG| January|        1|          41961|\n",
      "|   FATAL| January|        1|             94|\n",
      "|    INFO| January|        1|          29119|\n",
      "|    INFO|February|        2|          28983|\n",
      "|   DEBUG|February|        2|          41734|\n",
      "|   FATAL|February|        2|             72|\n",
      "|    WARN|February|        2|           8266|\n",
      "|   ERROR|February|        2|           4013|\n",
      "|    INFO|   March|        3|          29095|\n",
      "|   DEBUG|   March|        3|          41652|\n",
      "|   ERROR|   March|        3|           4122|\n",
      "|   FATAL|   March|        3|             70|\n",
      "|    WARN|   March|        3|           8165|\n",
      "|   FATAL|   April|        4|             83|\n",
      "|   ERROR|   April|        4|           4107|\n",
      "|   DEBUG|   April|        4|          41869|\n",
      "|    WARN|   April|        4|           8277|\n",
      "|    INFO|   April|        4|          29302|\n",
      "+--------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "int(date_format(logtime, 'M')) as month_num,\n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month, month_num\n",
    "order by month_num\"\"\").show()\n",
    "\n",
    "## Either mention the int(dateformat) or you can also do logtime, 'MM' to cast month as 01, 02 , 03 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "753bb5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------------+\n",
      "|loglevel|   month|month_num|total_occurence|\n",
      "+--------+--------+---------+---------------+\n",
      "|   DEBUG| January|       01|          41961|\n",
      "|    WARN| January|       01|           8217|\n",
      "|    INFO| January|       01|          29119|\n",
      "|   ERROR| January|       01|           4054|\n",
      "|   FATAL| January|       01|             94|\n",
      "|   FATAL|February|       02|             72|\n",
      "|    WARN|February|       02|           8266|\n",
      "|   ERROR|February|       02|           4013|\n",
      "|    INFO|February|       02|          28983|\n",
      "|   DEBUG|February|       02|          41734|\n",
      "|   DEBUG|   March|       03|          41652|\n",
      "|    WARN|   March|       03|           8165|\n",
      "|   ERROR|   March|       03|           4122|\n",
      "|   FATAL|   March|       03|             70|\n",
      "|    INFO|   March|       03|          29095|\n",
      "|   DEBUG|   April|       04|          41869|\n",
      "|    WARN|   April|       04|           8277|\n",
      "|    INFO|   April|       04|          29302|\n",
      "|   FATAL|   April|       04|             83|\n",
      "|   ERROR|   April|       04|           4107|\n",
      "+--------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "date_format(logtime, 'MM') as month_num,\n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month, month_num\n",
    "order by month_num\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fcc800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month, \n",
    "date_format(logtime, 'MM') as month_num,\n",
    "count(*) as total_occurence \n",
    "from serverlogs \n",
    "group by loglevel, month, month_num\n",
    "order by month_num\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22922139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------------+\n",
      "|loglevel|   month|month_num|total_occurence|\n",
      "+--------+--------+---------+---------------+\n",
      "|    INFO| January|       01|          29119|\n",
      "|   FATAL| January|       01|             94|\n",
      "|   DEBUG| January|       01|          41961|\n",
      "|    WARN| January|       01|           8217|\n",
      "|   ERROR| January|       01|           4054|\n",
      "|   DEBUG|February|       02|          41734|\n",
      "|   ERROR|February|       02|           4013|\n",
      "|   FATAL|February|       02|             72|\n",
      "|    WARN|February|       02|           8266|\n",
      "|    INFO|February|       02|          28983|\n",
      "|   DEBUG|   March|       03|          41652|\n",
      "|    WARN|   March|       03|           8165|\n",
      "|   FATAL|   March|       03|             70|\n",
      "|   ERROR|   March|       03|           4122|\n",
      "|    INFO|   March|       03|          29095|\n",
      "|   DEBUG|   April|       04|          41869|\n",
      "|   FATAL|   April|       04|             83|\n",
      "|    WARN|   April|       04|           8277|\n",
      "|    INFO|   April|       04|          29302|\n",
      "|   ERROR|   April|       04|           4107|\n",
      "+--------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96f86e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = result_df.drop(\"month_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9b5a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|loglevel|   month|total_occurence|\n",
      "+--------+--------+---------------+\n",
      "|    INFO| January|          29119|\n",
      "|   DEBUG| January|          41961|\n",
      "|    WARN| January|           8217|\n",
      "|   ERROR| January|           4054|\n",
      "|   FATAL| January|             94|\n",
      "|   DEBUG|February|          41734|\n",
      "|   FATAL|February|             72|\n",
      "|   ERROR|February|           4013|\n",
      "|    WARN|February|           8266|\n",
      "|    INFO|February|          28983|\n",
      "|   ERROR|   March|           4122|\n",
      "|    WARN|   March|           8165|\n",
      "|   DEBUG|   March|          41652|\n",
      "|   FATAL|   March|             70|\n",
      "|    INFO|   March|          29095|\n",
      "|   DEBUG|   April|          41869|\n",
      "|   FATAL|   April|             83|\n",
      "|    INFO|   April|          29302|\n",
      "|    WARN|   April|           8277|\n",
      "|   ERROR|   April|           4107|\n",
      "+--------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efb486",
   "metadata": {},
   "source": [
    "### Seeing the above results in pivot table will make it easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62d8934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|loglevel|April|August|December|February|January| July| June|March|  May|November|October|September|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|    INFO|29302| 28993|   28874|   28983|  29119|29300|29143|29095|28900|   23301|  29018|    29038|\n",
      "|   ERROR| 4107|  3987|    4106|    4013|   4054| 3976| 4059| 4122| 4086|    3389|   4040|     4161|\n",
      "|    WARN| 8277|  8381|    8328|    8266|   8217| 8222| 8191| 8165| 8403|    6616|   8226|     8352|\n",
      "|   FATAL|   83|    80|      94|      72|     94|   98|   78|   70|   60|   16797|     92|       81|\n",
      "|   DEBUG|41869| 42147|   41749|   41734|  41961|42085|41774|41652|41785|   33366|  41936|    41433|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month \n",
    "from serverlogs\"\"\") \\\n",
    ".groupBy('loglevel') \\\n",
    ".pivot('month') \\\n",
    ".count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42268bc",
   "metadata": {},
   "source": [
    "### Optimizing for better Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9cfeb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|loglevel|   01|   02|   03|   04|   05|   06|   07|   08|   09|   10|   11|   12|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|    INFO|29119|28983|29095|29302|28900|29143|29300|28993|29038|29018|23301|28874|\n",
      "|   ERROR| 4054| 4013| 4122| 4107| 4086| 4059| 3976| 3987| 4161| 4040| 3389| 4106|\n",
      "|    WARN| 8217| 8266| 8165| 8277| 8403| 8191| 8222| 8381| 8352| 8226| 6616| 8328|\n",
      "|   DEBUG|41961|41734|41652|41869|41785|41774|42085|42147|41433|41936|33366|41749|\n",
      "|   FATAL|   94|   72|   70|   83|   60|   78|   98|   80|   81|   92|16797|   94|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MM') as month \n",
    "from serverlogs\"\"\") \\\n",
    ".groupBy('loglevel') \\\n",
    ".pivot('month') \\\n",
    ".count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd656baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['January','February','March','April','May','June','July','August','September','October','November','December',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea1956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|loglevel|January|February|March|April|  May| June| July|August|September|October|November|December|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|    INFO|  29119|   28983|29095|29302|28900|29143|29300| 28993|    29038|  29018|   23301|   28874|\n",
      "|   ERROR|   4054|    4013| 4122| 4107| 4086| 4059| 3976|  3987|     4161|   4040|    3389|    4106|\n",
      "|    WARN|   8217|    8266| 8165| 8277| 8403| 8191| 8222|  8381|     8352|   8226|    6616|    8328|\n",
      "|   FATAL|     94|      72|   70|   83|   60|   78|   98|    80|       81|     92|   16797|      94|\n",
      "|   DEBUG|  41961|   41734|41652|41869|41785|41774|42085| 42147|    41433|  41936|   33366|   41749|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select loglevel, \n",
    "date_format(logtime, 'MMMM') as month \n",
    "from serverlogs\"\"\") \\\n",
    ".groupBy('loglevel') \\\n",
    ".pivot('month', month_list) \\\n",
    ".count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f9e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
