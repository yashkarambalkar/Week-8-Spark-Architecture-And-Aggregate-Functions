{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55b9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a2d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = [(\"DEBUG\",\"2014-6-22 21:30:49\"),\n",
    "(\"WARN\",\"2013-12-6 17:54:15\"),\n",
    "(\"DEBUG\",\"2017-1-12 10:47:02\"),\n",
    "(\"DEBUG\",\"2016-6-25 11:06:42\"),\n",
    "(\"ERROR\",\"2015-6-28 19:25:05\"),\n",
    "(\"DEBUG\",\"2012-6-24 01:06:37\"),\n",
    "(\"INFO\",\"2014-12-9 09:53:54\"),\n",
    "(\"DEBUG\",\"2015-11-8 19:20:08\"),\n",
    "(\"INFO\",\"2017-12-21 18:34:18\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b14d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.createDataFrame(logs_data).toDF('loglevel','logtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e587925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG| 2014-6-22 21:30:49|\n",
      "|    WARN| 2013-12-6 17:54:15|\n",
      "|   DEBUG| 2017-1-12 10:47:02|\n",
      "|   DEBUG| 2016-6-25 11:06:42|\n",
      "|   ERROR| 2015-6-28 19:25:05|\n",
      "|   DEBUG| 2012-6-24 01:06:37|\n",
      "|    INFO| 2014-12-9 09:53:54|\n",
      "|   DEBUG| 2015-11-8 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e4d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e68696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8572047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log_df = log_df.withColumn(\"logtime\", to_timestamp(\"logtime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02c7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loglevel: string (nullable = true)\n",
      " |-- logtime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a08601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_log_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c4054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|   DEBUG|2014-06-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-12-21 18:34:18|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dda8af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|loglevel|   month|total_occurence|\n",
      "+--------+--------+---------------+\n",
      "|    WARN|December|              1|\n",
      "|   ERROR|    June|              1|\n",
      "|   DEBUG| January|              1|\n",
      "|   DEBUG|November|              1|\n",
      "|   DEBUG|    June|              3|\n",
      "|    INFO|December|              2|\n",
      "+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, count(*) as total_occurence from serverlogs group by loglevel,month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2958886",
   "metadata": {},
   "outputs": [],
   "source": [
    "logschema = \"loglevel string, logtime timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3355ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(logschema) \\\n",
    ".load(\"/public/trendytech/datasets/logdata1m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac36bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df374927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db2dc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78750ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a978b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc60acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------------+\n",
      "|loglevel|    month|total_occurences|\n",
      "+--------+---------+----------------+\n",
      "|    WARN|     June|            8191|\n",
      "|    INFO|     June|           29143|\n",
      "|   ERROR| November|            3389|\n",
      "|   FATAL|  January|              94|\n",
      "|    WARN| December|            8328|\n",
      "|    WARN|    March|            8165|\n",
      "|   DEBUG|     July|           42085|\n",
      "|   ERROR|    April|            4107|\n",
      "|   ERROR|  January|            4054|\n",
      "|   FATAL|September|              81|\n",
      "|   FATAL|    April|              83|\n",
      "|    INFO|September|           29038|\n",
      "|   FATAL| November|           16797|\n",
      "|   FATAL|  October|              92|\n",
      "|    INFO| February|           28983|\n",
      "|    WARN|    April|            8277|\n",
      "|   DEBUG| December|           41749|\n",
      "|   FATAL| December|              94|\n",
      "|    WARN|      May|            8403|\n",
      "|   ERROR|     June|            4059|\n",
      "+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, count(*) as total_occurences from serverlogs group by loglevel,month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6590f081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------------+\n",
      "|loglevel|   month|total_occurences|\n",
      "+--------+--------+----------------+\n",
      "|   FATAL|   April|              83|\n",
      "|    INFO|   April|           29302|\n",
      "|    WARN|   April|            8277|\n",
      "|   ERROR|   April|            4107|\n",
      "|   DEBUG|   April|           41869|\n",
      "|    INFO|  August|           28993|\n",
      "|   FATAL|  August|              80|\n",
      "|   ERROR|  August|            3987|\n",
      "|   DEBUG|  August|           42147|\n",
      "|    WARN|  August|            8381|\n",
      "|    WARN|December|            8328|\n",
      "|   ERROR|December|            4106|\n",
      "|   DEBUG|December|           41749|\n",
      "|    INFO|December|           28874|\n",
      "|   FATAL|December|              94|\n",
      "|    WARN|February|            8266|\n",
      "|   FATAL|February|              72|\n",
      "|   DEBUG|February|           41734|\n",
      "|    INFO|February|           28983|\n",
      "|   ERROR|February|            4013|\n",
      "+--------+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, count(*) as total_occurences from serverlogs group by loglevel,month order by month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f76290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|   DEBUG| January|        1|           41961|\n",
      "|   ERROR| January|        1|            4054|\n",
      "|    INFO| January|        1|           29119|\n",
      "|    WARN| January|        1|            8217|\n",
      "|   FATAL| January|        1|              94|\n",
      "|    WARN| October|       10|            8226|\n",
      "|   ERROR| October|       10|            4040|\n",
      "|   FATAL| October|       10|              92|\n",
      "|   DEBUG| October|       10|           41936|\n",
      "|    INFO| October|       10|           29018|\n",
      "|   DEBUG|November|       11|           33366|\n",
      "|   ERROR|November|       11|            3389|\n",
      "|    INFO|November|       11|           23301|\n",
      "|   FATAL|November|       11|           16797|\n",
      "|    WARN|November|       11|            6616|\n",
      "|    INFO|December|       12|           28874|\n",
      "|   ERROR|December|       12|            4106|\n",
      "|   FATAL|December|       12|              94|\n",
      "|    WARN|December|       12|            8328|\n",
      "|   DEBUG|December|       12|           41749|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, date_format(logtime, 'M') as month_num, count(*) as total_occurences from serverlogs group by loglevel,month, month_num order by month_num\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6544a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|    WARN| January|        1|            8217|\n",
      "|   FATAL| January|        1|              94|\n",
      "|   DEBUG| January|        1|           41961|\n",
      "|    INFO| January|        1|           29119|\n",
      "|   ERROR| January|        1|            4054|\n",
      "|    INFO|February|        2|           28983|\n",
      "|    WARN|February|        2|            8266|\n",
      "|   DEBUG|February|        2|           41734|\n",
      "|   ERROR|February|        2|            4013|\n",
      "|   FATAL|February|        2|              72|\n",
      "|    INFO|   March|        3|           29095|\n",
      "|   FATAL|   March|        3|              70|\n",
      "|   DEBUG|   March|        3|           41652|\n",
      "|    WARN|   March|        3|            8165|\n",
      "|   ERROR|   March|        3|            4122|\n",
      "|   DEBUG|   April|        4|           41869|\n",
      "|   FATAL|   April|        4|              83|\n",
      "|    INFO|   April|        4|           29302|\n",
      "|    WARN|   April|        4|            8277|\n",
      "|   ERROR|   April|        4|            4107|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, int(date_format(logtime, 'M')) as month_num, count(*) as total_occurences from serverlogs group by loglevel,month, month_num order by month_num\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e77d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|   DEBUG| January|       01|           41961|\n",
      "|    INFO| January|       01|           29119|\n",
      "|    WARN| January|       01|            8217|\n",
      "|   ERROR| January|       01|            4054|\n",
      "|   FATAL| January|       01|              94|\n",
      "|    WARN|February|       02|            8266|\n",
      "|   FATAL|February|       02|              72|\n",
      "|   DEBUG|February|       02|           41734|\n",
      "|   ERROR|February|       02|            4013|\n",
      "|    INFO|February|       02|           28983|\n",
      "|   ERROR|   March|       03|            4122|\n",
      "|   DEBUG|   March|       03|           41652|\n",
      "|   FATAL|   March|       03|              70|\n",
      "|    WARN|   March|       03|            8165|\n",
      "|    INFO|   March|       03|           29095|\n",
      "|    WARN|   April|       04|            8277|\n",
      "|   FATAL|   April|       04|              83|\n",
      "|   DEBUG|   April|       04|           41869|\n",
      "|    INFO|   April|       04|           29302|\n",
      "|   ERROR|   April|       04|            4107|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, date_format(logtime, 'MM') as month_num, count(*) as total_occurences from serverlogs group by loglevel,month, month_num order by month_num\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16cb27f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|    INFO| January|       01|           29119|\n",
      "|   ERROR| January|       01|            4054|\n",
      "|   FATAL| January|       01|              94|\n",
      "|    WARN| January|       01|            8217|\n",
      "|   DEBUG| January|       01|           41961|\n",
      "|   ERROR|February|       02|            4013|\n",
      "|   DEBUG|February|       02|           41734|\n",
      "|   FATAL|February|       02|              72|\n",
      "|    INFO|February|       02|           28983|\n",
      "|    WARN|February|       02|            8266|\n",
      "|   ERROR|   March|       03|            4122|\n",
      "|    WARN|   March|       03|            8165|\n",
      "|    INFO|   March|       03|           29095|\n",
      "|   DEBUG|   March|       03|           41652|\n",
      "|   FATAL|   March|       03|              70|\n",
      "|    WARN|   April|       04|            8277|\n",
      "|   ERROR|   April|       04|            4107|\n",
      "|   FATAL|   April|       04|              83|\n",
      "|    INFO|   April|       04|           29302|\n",
      "|   DEBUG|   April|       04|           41869|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, first(date_format(logtime, 'MM')) as month_num, count(*) as total_occurences from serverlogs group by loglevel,month order by month_num\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e82efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month, first(date_format(logtime, 'MM')) as month_num, count(*) as total_occurences from serverlogs group by loglevel,month order by month_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0687e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------------+\n",
      "|loglevel|   month|month_num|total_occurences|\n",
      "+--------+--------+---------+----------------+\n",
      "|    WARN| January|       01|            8217|\n",
      "|   FATAL| January|       01|              94|\n",
      "|    INFO| January|       01|           29119|\n",
      "|   ERROR| January|       01|            4054|\n",
      "|   DEBUG| January|       01|           41961|\n",
      "|    WARN|February|       02|            8266|\n",
      "|   DEBUG|February|       02|           41734|\n",
      "|   FATAL|February|       02|              72|\n",
      "|    INFO|February|       02|           28983|\n",
      "|   ERROR|February|       02|            4013|\n",
      "|   ERROR|   March|       03|            4122|\n",
      "|   FATAL|   March|       03|              70|\n",
      "|   DEBUG|   March|       03|           41652|\n",
      "|    WARN|   March|       03|            8165|\n",
      "|    INFO|   March|       03|           29095|\n",
      "|   ERROR|   April|       04|            4107|\n",
      "|   FATAL|   April|       04|              83|\n",
      "|    WARN|   April|       04|            8277|\n",
      "|    INFO|   April|       04|           29302|\n",
      "|   DEBUG|   April|       04|           41869|\n",
      "+--------+--------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f35dcb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = result_df.drop(\"month_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d9e43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------------+\n",
      "|loglevel|   month|total_occurences|\n",
      "+--------+--------+----------------+\n",
      "|   FATAL| January|              94|\n",
      "|    WARN| January|            8217|\n",
      "|   ERROR| January|            4054|\n",
      "|   DEBUG| January|           41961|\n",
      "|    INFO| January|           29119|\n",
      "|   ERROR|February|            4013|\n",
      "|   FATAL|February|              72|\n",
      "|    INFO|February|           28983|\n",
      "|    WARN|February|            8266|\n",
      "|   DEBUG|February|           41734|\n",
      "|   ERROR|   March|            4122|\n",
      "|    INFO|   March|           29095|\n",
      "|    WARN|   March|            8165|\n",
      "|   DEBUG|   March|           41652|\n",
      "|   FATAL|   March|              70|\n",
      "|    WARN|   April|            8277|\n",
      "|   ERROR|   April|            4107|\n",
      "|    INFO|   April|           29302|\n",
      "|   DEBUG|   April|           41869|\n",
      "|   FATAL|   April|              83|\n",
      "+--------+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07894568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel,date_format(logtime,'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06beda0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|loglevel|April|August|December|February|January| July| June|March|  May|November|October|September|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|    INFO|29302| 28993|   28874|   28983|  29119|29300|29143|29095|28900|   23301|  29018|    29038|\n",
      "|   ERROR| 4107|  3987|    4106|    4013|   4054| 3976| 4059| 4122| 4086|    3389|   4040|     4161|\n",
      "|    WARN| 8277|  8381|    8328|    8266|   8217| 8222| 8191| 8165| 8403|    6616|   8226|     8352|\n",
      "|   DEBUG|41869| 42147|   41749|   41734|  41961|42085|41774|41652|41785|   33366|  41936|    41433|\n",
      "|   FATAL|   83|    80|      94|      72|     94|   98|   78|   70|   60|   16797|     92|       81|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel,date_format(logtime,'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a31bcd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|loglevel|   01|   02|   03|   04|   05|   06|   07|   08|   09|   10|   11|   12|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|    INFO|29119|28983|29095|29302|28900|29143|29300|28993|29038|29018|23301|28874|\n",
      "|   ERROR| 4054| 4013| 4122| 4107| 4086| 4059| 3976| 3987| 4161| 4040| 3389| 4106|\n",
      "|    WARN| 8217| 8266| 8165| 8277| 8403| 8191| 8222| 8381| 8352| 8226| 6616| 8328|\n",
      "|   DEBUG|41961|41734|41652|41869|41785|41774|42085|42147|41433|41936|33366|41749|\n",
      "|   FATAL|   94|   72|   70|   83|   60|   78|   98|   80|   81|   92|16797|   94|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel,date_format(logtime,'MM') as month from serverlogs\").groupBy('loglevel').pivot('month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af2c8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list=['January','February','March','April','May','June','July','August','September','October','November','December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58edce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|loglevel|January|February|March|April|  May| June| July|August|September|October|November|December|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|    INFO|  29119|   28983|29095|29302|28900|29143|29300| 28993|    29038|  29018|   23301|   28874|\n",
      "|   ERROR|   4054|    4013| 4122| 4107| 4086| 4059| 3976|  3987|     4161|   4040|    3389|    4106|\n",
      "|    WARN|   8217|    8266| 8165| 8277| 8403| 8191| 8222|  8381|     8352|   8226|    6616|    8328|\n",
      "|   FATAL|     94|      72|   70|   83|   60|   78|   98|    80|       81|     92|   16797|      94|\n",
      "|   DEBUG|  41961|   41734|41652|41869|41785|41774|42085| 42147|    41433|  41936|   33366|   41749|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel,date_format(logtime,'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('month',month_list).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00c8654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list=['Jan','February','March','April','May','June','July','August','September','October','November','December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a74ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|loglevel| Jan|February|March|April|  May| June| July|August|September|October|November|December|\n",
      "+--------+----+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|    INFO|null|   28983|29095|29302|28900|29143|29300| 28993|    29038|  29018|   23301|   28874|\n",
      "|   ERROR|null|    4013| 4122| 4107| 4086| 4059| 3976|  3987|     4161|   4040|    3389|    4106|\n",
      "|    WARN|null|    8266| 8165| 8277| 8403| 8191| 8222|  8381|     8352|   8226|    6616|    8328|\n",
      "|   FATAL|null|      72|   70|   83|   60|   78|   98|    80|       81|     92|   16797|      94|\n",
      "|   DEBUG|null|   41734|41652|41869|41785|41774|42085| 42147|    41433|  41936|   33366|   41749|\n",
      "+--------+----+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel,date_format(logtime,'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('month',month_list).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9576d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
